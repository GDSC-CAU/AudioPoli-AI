{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98827cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/GDSC_AudioPoli\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e5c3737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from capsulelayers import CapsuleLayer, PrimaryCap, Distance, Mask\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "# import seaborn as sn\n",
    "# import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "# import pandas as pd\n",
    "import numpy as np\n",
    "import sys; sys.argv=['']; del sys\n",
    "import argparse\n",
    "import h5py\n",
    "import time\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c6879b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CapsNet margin loss\n",
    "def margin_loss(y_true, y_pred):\n",
    "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "    return K.mean(K.sum(L, 1))\n",
    "\n",
    "# predict\n",
    "def test_one(model, data, args):\n",
    "    x_test, y_test = data\n",
    "    start = time.time()\n",
    "    y_pred, x_recon = model.predict(x_test, batch_size=100)\n",
    "    print('\\nPrediction response time : ', time.time() - start)\n",
    "    print('Test accuracy:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1)) / y_test.shape[0])\n",
    "\n",
    "# preprocess data\n",
    "def detect_index(name):\n",
    "    index = name.split('.')[1].split('_')[0]\n",
    "    if index == '강제추행(성범죄)':\n",
    "        index = 1\n",
    "    elif index == '강도범죄':\n",
    "        index = 2\n",
    "    elif index == '절도범죄':\n",
    "        index = 3\n",
    "    elif index == '폭력범죄':\n",
    "        index = 4\n",
    "    elif index == '화재':\n",
    "        index = 5\n",
    "    elif index == '갇힘':\n",
    "        index = 6\n",
    "    elif index == '응급의료':\n",
    "        index = 7\n",
    "    elif index == '전기사고':\n",
    "        index = 8\n",
    "    elif index == '가스사고':\n",
    "        index = 9\n",
    "    elif index == '낙상':\n",
    "        index = 10\n",
    "    elif index == '붕괴사고':\n",
    "        index = 11\n",
    "    elif index == '태풍-강풍':\n",
    "        index = 12\n",
    "    elif index == '지진':\n",
    "        index = 13\n",
    "    elif index == '도움요청':\n",
    "        index = 14\n",
    "    elif index == '실내':\n",
    "        index = 15\n",
    "    elif index == '실외':\n",
    "        index = 16\n",
    "    else:\n",
    "        pass\n",
    "    return index\n",
    "\n",
    "def test_graph(model, data, args):\n",
    "    labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "    ''' A:강제추행, B:강도범죄, C:절도범죄, D:폭력범죄, \n",
    "    E:화재, F:갇힘, G:응급의료, H:전기사고, \n",
    "    I:가스사고, J:낙상, K:붕괴사고, L:태풍/강풍, \n",
    "    M:지진, N:도움요청, O:실내, P:실외 \n",
    "    '''\n",
    "    x_test, y_test = data\n",
    "    y_pred, x_recon = model.predict(x_test, batch_size=20)\n",
    "    cm = confusion_matrix(np.argmax(y_test, 1), np.argmax(y_pred, 1))\n",
    "    print('\\nCategory Classification Report\\n')\n",
    "    print(classification_report(np.argmax(y_test, 1), np.argmax(y_pred, 1), target_names=labels))\n",
    "    print('\\nConfusion Matrix graph saved', model_save)\n",
    "    return cm, labels\n",
    "\n",
    "# read HDF5 file\n",
    "def test_dataset():\n",
    "    x_train_mfcc = []\n",
    "    y_train_mfcc = []\n",
    "    for i in range(0, label):  # 1~16 label\n",
    "        for ds_name in ['mfcc', 'y']:\n",
    "            if ds_name == 'mfcc':\n",
    "                count = \"mfcc_y_%ix%i_%i\" % (height, width, i)\n",
    "                mfcc = h5py.File(save_HDF + count + '.h5', 'r')\n",
    "                x_train_mfcc.extend(mfcc[ds_name])\n",
    "            if ds_name == 'y':\n",
    "                count = \"mfcc_y_%ix%i_%i\" % (height, width, i)\n",
    "                mfcc = h5py.File(save_HDF + count + '.h5', 'r')\n",
    "                y_train_mfcc.extend(mfcc[ds_name])\n",
    "    # reshape\n",
    "    test_x = np.array(x_train_mfcc)\n",
    "    test_y = np.array(y_train_mfcc)\n",
    "    test_x = test_x.reshape(-1, height, width, 1)\n",
    "    test_y = np.argmax(test_y, axis=1).reshape(-1)\n",
    "    test_y = test_y[:, None]\n",
    "    test_y = to_categorical(test_y.astype('float32'))\n",
    "    return (test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ea10e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import initializers, layers\n",
    "\n",
    "\n",
    "class Distance(layers.Layer):\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return K.sqrt(K.sum(K.square(inputs), -1) + K.epsilon())\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Distance, self).get_config()\n",
    "        return config\n",
    "\n",
    "\n",
    "class Mask(layers.Layer):\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if type(inputs) is list:  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n",
    "            assert len(inputs) == 2\n",
    "            inputs, mask = inputs\n",
    "        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n",
    "            # compute lengths of capsules\n",
    "            x = K.sqrt(K.sum(K.square(inputs), -1))\n",
    "            # generate the mask which is a one-hot code.\n",
    "            # mask.shape=[None, n_classes]=[None, num_capsule]\n",
    "            mask = K.one_hot(indices=K.argmax(x, 1), num_classes=x.get_shape().as_list()[1])\n",
    "\n",
    "        # inputs.shape=[None, num_capsule, dim_capsule]\n",
    "        # mask.shape=[None, num_capsule]\n",
    "        # masked.shape=[None, num_capsule * dim_capsule]\n",
    "        masked = K.batch_flatten(inputs * K.expand_dims(mask, -1))\n",
    "        return masked\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if type(input_shape[0]) is tuple:  # true label provided\n",
    "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
    "        else:  # no true label provided\n",
    "            return tuple([None, input_shape[1] * input_shape[2]])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Mask, self).get_config()\n",
    "        return config\n",
    "\n",
    "\n",
    "def squash(vectors, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
    "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return scale * vectors\n",
    "\n",
    "\n",
    "class CapsuleLayer(layers.Layer):\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n",
    "        self.input_num_capsule = input_shape[1]\n",
    "        self.input_dim_capsule = input_shape[2]\n",
    "\n",
    "        # Transform matrix\n",
    "        self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n",
    "                                        self.dim_capsule, self.input_dim_capsule],\n",
    "                                 initializer=self.kernel_initializer,\n",
    "                                 name='W')\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # inputs.shape=[None, input_num_capsule, input_dim_capsule]\n",
    "        # inputs_expand.shape=[None, 1, input_num_capsule, input_dim_capsule]\n",
    "        inputs_expand = K.expand_dims(inputs, 1)\n",
    "\n",
    "        # Replicate num_capsule dimension to prepare being multiplied by W\n",
    "        # inputs_tiled.shape=[None, num_capsule, input_num_capsule, input_dim_capsule]\n",
    "        inputs_tiled = K.tile(inputs_expand, [1, self.num_capsule, 1, 1])\n",
    "\n",
    "        # Compute `inputs * W` by scanning inputs_tiled on dimension 0.\n",
    "        # x.shape=[num_capsule, input_num_capsule, input_dim_capsule]\n",
    "        # W.shape=[num_capsule, input_num_capsule, dim_capsule, input_dim_capsule]\n",
    "        # Regard the first two dimensions as `batch` dimension,\n",
    "        # then matmul: [input_dim_capsule] x [dim_capsule, input_dim_capsule]^T -> [dim_capsule].\n",
    "        # inputs_hat.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "        inputs_hat = K.map_fn(lambda x: K.batch_dot(x, self.W, [2, 3]), elems=inputs_tiled)\n",
    "\n",
    "        # Begin: Routing algorithm ---------------------------------------------------------------------#\n",
    "        # The prior for coupling coefficient, initialized as zeros.\n",
    "        # b.shape = [None, self.num_capsule, self.input_num_capsule].\n",
    "        b = tf.zeros(shape=[K.shape(inputs_hat)[0], self.num_capsule, self.input_num_capsule])\n",
    "\n",
    "        assert self.routings > 0, 'The routings should be > 0.'\n",
    "        for i in range(self.routings):\n",
    "            # c.shape=[batch_size, num_capsule, input_num_capsule]\n",
    "            c = tf.nn.softmax(b, dim=1)\n",
    "\n",
    "            # c.shape =  [batch_size, num_capsule, input_num_capsule]\n",
    "            # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
    "            # The first two dimensions as `batch` dimension,\n",
    "            # then matmal: [input_num_capsule] x [input_num_capsule, dim_capsule] -> [dim_capsule].\n",
    "            # outputs.shape=[None, num_capsule, dim_capsule]\n",
    "            outputs = squash(K.batch_dot(c, inputs_hat, [2, 2]))  # [None, 10, 16]\n",
    "\n",
    "            if i < self.routings - 1:\n",
    "                # outputs.shape =  [None, num_capsule, dim_capsule]\n",
    "                # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
    "                # The first two dimensions as `batch` dimension,\n",
    "                # then matmal: [dim_capsule] x [input_num_capsule, dim_capsule]^T -> [input_num_capsule].\n",
    "                # b.shape=[batch_size, num_capsule, input_num_capsule]\n",
    "                b += K.batch_dot(outputs, inputs_hat, [2, 3])\n",
    "        # End: Routing algorithm -----------------------------------------------------------------------#\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple([None, self.num_capsule, self.dim_capsule])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'num_capsule': self.num_capsule,\n",
    "            'dim_capsule': self.dim_capsule,\n",
    "            'routings': self.routings\n",
    "        }\n",
    "        base_config = super(CapsuleLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
    "    output = layers.Conv2D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding,\n",
    "                           name='primarycap_conv2d')(inputs)\n",
    "    outputs = layers.Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(output)\n",
    "    return layers.Lambda(squash, name='primarycap_squash')(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8b489b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jihwan/miniconda3/envs/AudioPoli_oldies/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jihwan/miniconda3/envs/AudioPoli_oldies/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 48, 173, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 24, 58, 8)    208         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 20, 27, 256)  51456       conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_conv2d (Conv2D)      (None, 6, 10, 256)   5308672     conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_reshape (Reshape)    (None, 1920, 8)      0           primarycap_conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_squash (Lambda)      (None, 1920, 8)      0           primarycap_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "class_caps (CapsuleLayer)       (None, 16, 16)       3932160     primarycap_squash[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mask_2 (Mask)                   (None, 256)          0           class_caps[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "capsnet (Distance)              (None, 16)           0           class_caps[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Sequential)            (None, 48, 173, 1)   9168496     mask_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 18,460,992\n",
      "Trainable params: 18,460,992\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "eval_model = load_model('./eval.h5',\n",
    "                            custom_objects={'CapsuleLayer': CapsuleLayer, 'Mask': Mask, 'Distance': Distance,\n",
    "                                            'PrimaryCab': PrimaryCap, 'margin_loss': margin_loss})\n",
    "eval_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "eval_model.summary()\n",
    "eval_model.save('./eval_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf77f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('eval.pkl', 'wb') as f:\n",
    "    pickle.dump(eval_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c9ec2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a2d39f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c3fd1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from capsulelayers import CapsuleLayer, PrimaryCap, Distance, Mask\n",
    "from tensorflow import keras\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys; sys.argv=['']; del sys\n",
    "import argparse\n",
    "import h5py\n",
    "import time\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb49d6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras                        2.14.0\r\n",
      "tensorflow                   2.14.0\r\n",
      "tensorflow-estimator         2.14.0\r\n",
      "tensorflow-io-gcs-filesystem 0.35.0\r\n"
     ]
    }
   ],
   "source": [
    "! pip list | grep -E '(keras|tensorflow)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1be089ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.engine'"
     ]
    }
   ],
   "source": [
    "with open('eval.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14386b94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AudioPoli",
   "language": "python",
   "name": "audiopoli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
